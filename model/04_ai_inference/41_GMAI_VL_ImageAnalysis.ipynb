{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMAI-VL ì˜ë£Œ ì˜ìƒ ë¶„ì„\n",
    "\n",
    "> **Purpose:** GMAI-VL(General Medical AI Vision-Language) ëª¨ë¸ì„ í™œìš©í•˜ì—¬\n",
    "> ì˜ë£Œ ì˜ìƒ(CT, MRI, X-ray)ê³¼ ì„ìƒ í…ìŠ¤íŠ¸ë¥¼ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.\n",
    ">\n",
    "> **ëª¨ë¸ ì‚¬ì–‘:**\n",
    "> - êµ¬ì¡°: Vision Encoder (ViT-L/14) + Text Encoder (BERT-base) + Cross-Attention\n",
    "> - í•™ìŠµ ë°ì´í„°: 550ë§Œ ê°œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ (PubMed, Radiopaedia)\n",
    "> - ê°•ì : ë‹¤ì–‘í•œ ì˜ë£Œ ì˜ìƒì—ì„œì˜ ì¼ë°˜ì  ë³‘ë³€ íƒì§€ ë° í•´ë¶€í•™ì  êµ¬ì¡° ì¸ì‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë¸ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# MLflow ëª¨ë¸ ë¡œë“œ (Model Registryì—ì„œ)\n",
    "# model = mlflow.pytorch.load_model(\"models:/gmai-vl/Production\")\n",
    "\n",
    "# ë˜ëŠ” HuggingFaceì—ì„œ ì§ì ‘ ë¡œë“œ\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "# model = AutoModel.from_pretrained(\"GMAI-VL-model-path\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"GMAI-VL-model-path\")\n",
    "\n",
    "print(\"ğŸ”§ GMAI-VL ëª¨ë¸ ì„¤ì • ì¤€ë¹„\")\n",
    "print(\"   â†’ MLflow Model Registry ë˜ëŠ” HuggingFaceì—ì„œ ë¡œë“œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ì˜ìƒ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_medical_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    ì˜ë£Œ ì˜ìƒì„ GMAI-VL ì…ë ¥ í˜•íƒœë¡œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        image_path: ADLS Gen2 ë‚´ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "        target_size: ëª¨ë¸ ì…ë ¥ í¬ê¸°\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img = img.resize(target_size)\n",
    "        \n",
    "        # ì •ê·œí™” (ImageNet í†µê³„ëŸ‰)\n",
    "        import torchvision.transforms as transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        return transform(img).unsqueeze(0)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… ì˜ìƒ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GMAI-VL ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gmai_vl_inference(image_tensor, clinical_context):\n",
    "    \"\"\"\n",
    "    GMAI-VL ëª¨ë¸ë¡œ ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        image_tensor: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ\n",
    "        clinical_context: í™˜ì ë°”ì´íƒˆ/ì¦ìƒ í…ìŠ¤íŠ¸\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            \"findings\": str,           # ë°œê²¬ ì‚¬í•­\n",
    "            \"abnormality_bbox\": list,   # ë³‘ë³€ ìœ„ì¹˜ (bounding box)\n",
    "            \"confidence\": float         # ì‹ ë¢°ë„\n",
    "        }\n",
    "    \"\"\"\n",
    "    # ëª¨ë¸ ì¶”ë¡  (ì‹¤ì œ êµ¬í˜„)\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model(image_tensor, clinical_context)\n",
    "    #     findings = outputs[\"text\"]\n",
    "    #     bbox = outputs[\"bbox\"]\n",
    "    #     confidence = outputs[\"confidence\"]\n",
    "    \n",
    "    # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ (ëª¨ë¸ ë¡œë“œ ì „ í…ŒìŠ¤íŠ¸ìš©)\n",
    "    result = {\n",
    "        \"findings\": \"Right middle lobe consolidation identified. No pleural effusion observed.\",\n",
    "        \"abnormality_bbox\": [120, 80, 200, 160],  # [x1, y1, x2, y2]\n",
    "        \"confidence\": 0.89,\n",
    "        \"modality\": \"CT\",\n",
    "        \"model_version\": \"GMAI-VL-v1.0\"\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ… GMAI-VL ì¶”ë¡  í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ë°°ì¹˜ ì˜ìƒ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_image_analysis(image_paths, clinical_contexts):\n",
    "    \"\"\"\n",
    "    ë‹¤ìˆ˜ì˜ ì˜ë£Œ ì˜ìƒì— ëŒ€í•´ GMAI-VL ë°°ì¹˜ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ê²°ê³¼ëŠ” Gold Layerì— ì €ì¥ë˜ì–´ OpenAI ì¶”ë¡ ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for img_path, context in zip(image_paths, clinical_contexts):\n",
    "        img_tensor = preprocess_medical_image(img_path)\n",
    "        \n",
    "        if img_tensor is not None:\n",
    "            result = gmai_vl_inference(img_tensor, context)\n",
    "            result[\"image_path\"] = img_path\n",
    "            results.append(result)\n",
    "    \n",
    "    if results:\n",
    "        df_results = spark.createDataFrame(results)\n",
    "        df_results = df_results.withColumn(\"analyzed_at\", F.current_timestamp())\n",
    "        \n",
    "        # Gold Layerì— ì €ì¥\n",
    "        df_results.write \\\n",
    "            .format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .saveAsTable(\"gold.image_analysis_results\")\n",
    "        \n",
    "        print(f\"âœ… ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {len(results)}ê±´\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… ë°°ì¹˜ ì˜ìƒ ë¶„ì„ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"â†’ 50_MLflow_Experiment_Setup.pyì—ì„œ ì‹¤í—˜ íŠ¸ë˜í‚¹ ì—°ë™\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}