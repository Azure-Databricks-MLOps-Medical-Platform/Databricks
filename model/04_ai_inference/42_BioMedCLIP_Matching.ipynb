{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BioMedCLIP ì˜ë£Œ ì˜ìƒ-í…ìŠ¤íŠ¸ ë§¤ì¹­\n",
                "\n",
                "> **Purpose:** BioMedCLIP ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì˜ë£Œ ì˜ìƒê³¼ ì¦ìƒ í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.\n",
                ">\n",
                "> **ëª¨ë¸:** `microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224`\n",
                "> - í•™ìŠµ ë°ì´í„°: PMC-15M (1,500ë§Œ ë°”ì´ì˜¤ë©”ë””ì»¬ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ)\n",
                "> - ì—­í• : ì˜ìƒ-ì¦ìƒ cross-modal retrieval + ìœ„ê¸‰ë„ í‰ê°€\n",
                "> - ê²°ê³¼ ì €ì¥: `P2T2.ai_results.biomedclip_results`\n",
                ">\n",
                "> **ì¹´íƒˆë¡œê·¸:** `P2T2`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. ì¹´íƒˆë¡œê·¸ ì„¤ì •"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.sql(\"USE CATALOG P2T2\")\n",
                "print(\"âœ… Catalog: P2T2\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë¸ ë¡œë“œ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "from pyspark.sql import functions as F\n",
                "\n",
                "# BioMedCLIP ëª¨ë¸ ë¡œë“œ\n",
                "# from open_clip import create_model_and_transforms, get_tokenizer\n",
                "# model, preprocess_train, preprocess_val = create_model_and_transforms(\n",
                "#     'hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224'\n",
                "# )\n",
                "# tokenizer = get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
                "\n",
                "print(\"ğŸ”§ BioMedCLIP ëª¨ë¸ ì„¤ì • ì¤€ë¹„\")\n",
                "print(\"   â†’ microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ì˜ìƒ-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def compute_similarity(image_features, text_features):\n",
                "    \"\"\"\n",
                "    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)\n",
                "    \"\"\"\n",
                "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
                "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
                "    similarity = (image_features @ text_features.T).item()\n",
                "    return max(0.0, min(1.0, similarity))\n",
                "\n",
                "print(\"âœ… ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Context Fusion (ë°”ì´íƒˆ + ì˜ìƒ)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def context_fusion(vital_data, image_analysis_result):\n",
                "    \"\"\"\n",
                "    BioMedCLIPì´ ë°”ì´íƒˆ ë°ì´í„°ì™€ ì˜ìƒ ë¶„ì„ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìœ„ê¸‰ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.\n",
                "    \n",
                "    ì‹¤ì œ ì»¬ëŸ¼: avg_heart_rate, avg_systolic_bp, avg_diastolic_bp, avg_spo2,\n",
                "              avg_temperature, avg_respiratory_rate, max_risk_score\n",
                "    \"\"\"\n",
                "    # í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
                "    clinical_text = f\"\"\"\n",
                "    Patient vitals: HR {vital_data.get('avg_heart_rate', 'N/A')} bpm, \n",
                "    BP {vital_data.get('avg_systolic_bp', 'N/A')}/{vital_data.get('avg_diastolic_bp', 'N/A')} mmHg,\n",
                "    SpO2 {vital_data.get('avg_spo2', 'N/A')}%,\n",
                "    Temp {vital_data.get('avg_temperature', 'N/A')}Â°C,\n",
                "    RR {vital_data.get('avg_respiratory_rate', 'N/A')}/min.\n",
                "    Risk score: {vital_data.get('max_risk_score', 'N/A')}/1.0.\n",
                "    Imaging findings: {image_analysis_result.get('findings', 'No findings available')}.\n",
                "    \"\"\"\n",
                "    \n",
                "    # í›„ë³´ ì§„ë‹¨ í…ìŠ¤íŠ¸ ëª©ë¡\n",
                "    candidate_diagnoses = [\n",
                "        \"Acute ischemic stroke with middle cerebral artery occlusion\",\n",
                "        \"Pulmonary embolism with right ventricular strain\",\n",
                "        \"Acute myocardial infarction with ST elevation\",\n",
                "        \"Pneumothorax with mediastinal shift\",\n",
                "        \"Normal findings, no acute pathology\",\n",
                "    ]\n",
                "    \n",
                "    # ìœ ì‚¬ë„ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜ â€” ì‹¤ì œ: BioMedCLIP ì„ë² ë”©)\n",
                "    results = []\n",
                "    for diagnosis in candidate_diagnoses:\n",
                "        similarity = np.random.uniform(0.3, 0.95)\n",
                "        results.append({\"diagnosis\": diagnosis, \"similarity\": round(similarity, 4)})\n",
                "    \n",
                "    results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
                "    \n",
                "    # ìœ„ê¸‰ë„ í‰ê°€\n",
                "    top_sim = results[0][\"similarity\"]\n",
                "    urgency = \"CRITICAL\" if top_sim > 0.8 else \"WARNING\" if top_sim > 0.5 else \"STABLE\"\n",
                "    \n",
                "    return {\n",
                "        \"patient_id\": vital_data.get(\"patient_id\"),\n",
                "        \"top_diagnosis\": results[0][\"diagnosis\"],\n",
                "        \"top_similarity\": str(results[0][\"similarity\"]),\n",
                "        \"urgency_level\": urgency,\n",
                "    }\n",
                "\n",
                "print(\"âœ… Context Fusion í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ë°°ì¹˜ ë§¤ì¹­ ë° ê²°ê³¼ ì €ì¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def batch_biomedclip_matching():\n",
                "    \"\"\"\n",
                "    Gold Layer í™˜ì ë°ì´í„°ì™€ DICOM ì˜ìƒ ë§¤ì¹­ í›„ P2T2.ai_resultsì— ì €ì¥í•©ë‹ˆë‹¤.\n",
                "    \"\"\"\n",
                "    df_patients = spark.table(\"P2T2.gold.patient_clinical_summary\").collect()\n",
                "    df_dicom = spark.table(\"P2T2.silver.cleaned_dicom_metadata\").collect()\n",
                "    \n",
                "    results = []\n",
                "    for p in df_patients:\n",
                "        vital_data = {k: str(v) if v is not None else \"N/A\" for k, v in p.asDict().items()}\n",
                "        d = next((d for d in df_dicom if d[\"patient_id\"] == p[\"patient_id\"]), None)\n",
                "        image_result = {\"findings\": d[\"finding_labels\"] if d else \"No DICOM available\"}\n",
                "        \n",
                "        result = context_fusion(vital_data, image_result)\n",
                "        results.append(result)\n",
                "    \n",
                "    if results:\n",
                "        df_results = spark.createDataFrame(results)\n",
                "        df_results = df_results.withColumn(\"created_at\", F.current_timestamp())\n",
                "        df_results.write \\\n",
                "            .format(\"delta\") \\\n",
                "            .mode(\"overwrite\") \\\n",
                "            .option(\"overwriteSchema\", \"true\") \\\n",
                "            .saveAsTable(\"P2T2.ai_results.biomedclip_results\")\n",
                "        print(f\"âœ… BioMedCLIP ë§¤ì¹­ ì €ì¥: {len(results)}ê±´ â†’ P2T2.ai_results.biomedclip_results\")\n",
                "    else:\n",
                "        print(\"âš ï¸ ë§¤ì¹­í•  í™˜ì ë°ì´í„° ì—†ìŒ\")\n",
                "\n",
                "batch_biomedclip_matching()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}