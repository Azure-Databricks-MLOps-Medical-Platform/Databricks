# -*- coding: utf-8 -*-
"""
ê¹€ì² ìˆ˜ (Kim Cheolsu) â€” Databricks Medallion Pipeline ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜
Bronze â†’ Silver â†’ Gold â†’ AI Inference â†’ LLM-as-a-Judge

Pandas ê¸°ë°˜ ì‹¤í–‰ (PySpark ë¡œì»¬ ëŒ€ì²´ - Hadoop winutils ë¯¸ì„¤ì¹˜ í™˜ê²½)
Databricksì—ì„œëŠ” ë™ì¼ ë¡œì§ì´ PySpark/Delta Lakeë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
"""
import os
import sys
import json
import shutil
import pandas as pd
import numpy as np
from datetime import datetime

# â”€â”€ ê²½ë¡œ ì„¤ì • â”€â”€
BASE = os.path.dirname(os.path.abspath(__file__))          # model/
PROJECT_ROOT = os.path.dirname(BASE)                        # Databricks/
PATIENT_DIR = os.path.join(PROJECT_ROOT, "data", "patient_kimcs")
OUTPUT_DIR = os.path.join(PROJECT_ROOT, "result")

if os.path.exists(OUTPUT_DIR):
    shutil.rmtree(OUTPUT_DIR)
os.makedirs(OUTPUT_DIR, exist_ok=True)

AGE = 58
GENDER = "Male"
BLOOD_TYPE = "A+"

print("=" * 70)
print("  Databricks Medallion Pipeline â€” ë¡œì»¬ ì‹œë®¬ë ˆì´ì…˜ (Pandas)")
print("  í™˜ì: ê¹€ì² ìˆ˜ (M00001) | ì§„ë‹¨: íê²°í•µ ê¸‰ì„± ë°œì‘")
print("=" * 70)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BRONZE LAYER â€” Raw Data Ingestion
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "â”" * 70)
print("  [BRONZE] Raw Data Ingestion â†’ Parquet ì ì¬")
print("â”" * 70)

# 1. Emergency Data
df_emergency = pd.read_csv(os.path.join(PATIENT_DIR, "emergency_data.csv"), encoding="utf-8-sig")
bronze_emergency_path = os.path.join(OUTPUT_DIR, "bronze", "emergency")
os.makedirs(bronze_emergency_path, exist_ok=True)
df_emergency.to_parquet(os.path.join(bronze_emergency_path, "data.parquet"), index=False)
print(f"  âœ“ Bronze Emergency: {len(df_emergency)} rows")

# 2. Medical History
df_history = pd.read_csv(os.path.join(PATIENT_DIR, "medical_history.csv"), encoding="utf-8-sig")
bronze_history_path = os.path.join(OUTPUT_DIR, "bronze", "medical_history")
os.makedirs(bronze_history_path, exist_ok=True)
df_history.to_parquet(os.path.join(bronze_history_path, "data.parquet"), index=False)
print(f"  âœ“ Bronze Medical History: {len(df_history)} rows")

# 3. Vital Signs
df_vitals = pd.read_csv(os.path.join(PATIENT_DIR, "vital_signs_timeseries.csv"), encoding="utf-8-sig")
bronze_vitals_path = os.path.join(OUTPUT_DIR, "bronze", "vital_logs")
os.makedirs(bronze_vitals_path, exist_ok=True)
df_vitals.to_parquet(os.path.join(bronze_vitals_path, "data.parquet"), index=False)
print(f"  âœ“ Bronze Vital Logs: {len(df_vitals)} rows (5ë¶„ ê°„ê²© Ã— 4ì‹œê°„)")

# 4. DICOM Metadata
df_dicom = pd.read_csv(os.path.join(PATIENT_DIR, "dicom_metadata.csv"), encoding="utf-8-sig")
bronze_dicom_path = os.path.join(OUTPUT_DIR, "bronze", "dicom_metadata")
os.makedirs(bronze_dicom_path, exist_ok=True)
df_dicom.to_parquet(os.path.join(bronze_dicom_path, "data.parquet"), index=False)
print(f"  âœ“ Bronze DICOM Metadata: {len(df_dicom)} rows")

print("\n  â”€â”€ Bronze Emergency Record â”€â”€")
print(df_emergency[["patient_name", "chief_complaint", "triage_level", "suspected_diagnosis"]].to_string(index=False))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SILVER LAYER â€” Data Refinement
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "â”" * 70)
print("  [SILVER] Data Refinement & Quality Checks")
print("â”" * 70)

# 1. Outlier Filtering
before_count = len(df_vitals)
df_vitals_filtered = df_vitals[
    (df_vitals["heart_rate"].between(30, 220)) &
    (df_vitals["systolic_bp"].between(60, 250)) &
    (df_vitals["diastolic_bp"].between(30, 150)) &
    (df_vitals["spo2"].between(50, 100)) &
    (df_vitals["temperature"].between(34.0, 42.0)) &
    (df_vitals["respiratory_rate"].between(5, 60))
].copy()
removed = before_count - len(df_vitals_filtered)
print(f"  Outlier filtering: {removed} rows removed ({len(df_vitals_filtered)} retained)")

# 2. Risk Level & Alert Flags
df_vitals_filtered["risk_level"] = pd.cut(
    df_vitals_filtered["risk_score"],
    bins=[-1, 20, 40, 60, 200],
    labels=["LOW", "MODERATE", "HIGH", "CRITICAL"]
)
df_vitals_filtered["alert_flag"] = (
    (df_vitals_filtered["spo2"] < 90) |
    (df_vitals_filtered["heart_rate"] > 120) |
    (df_vitals_filtered["temperature"] > 38.5) |
    (df_vitals_filtered["respiratory_rate"] > 25)
)

silver_vitals_path = os.path.join(OUTPUT_DIR, "silver", "refined_vitals")
os.makedirs(silver_vitals_path, exist_ok=True)
df_vitals_filtered.to_parquet(os.path.join(silver_vitals_path, "data.parquet"), index=False)

alert_count = int(df_vitals_filtered["alert_flag"].sum())
print(f"  âš  Alert flags: {alert_count}/{len(df_vitals_filtered)} measurements")

print("\n  Risk Level Distribution:")
risk_dist = df_vitals_filtered["risk_level"].value_counts().sort_index()
for level, cnt in risk_dist.items():
    bar = "â–ˆ" * int(cnt / len(df_vitals_filtered) * 40)
    print(f"    {level:10s}: {cnt:3d} ({cnt/len(df_vitals_filtered)*100:5.1f}%) {bar}")

# 3. Emergency Enrichment
df_emergency_silver = df_emergency.copy()
df_emergency_silver["response_time_min"] = 13
df_emergency_silver["scene_time_min"] = 10
df_emergency_silver["transport_time_min"] = 10
df_emergency_silver["total_prehospital_min"] = 33

silver_emergency_path = os.path.join(OUTPUT_DIR, "silver", "refined_emergency")
os.makedirs(silver_emergency_path, exist_ok=True)
df_emergency_silver.to_parquet(os.path.join(silver_emergency_path, "data.parquet"), index=False)
print(f"\n  âœ“ Silver Emergency: ëŒ€ì‘ {13}ë¶„ + í˜„ì¥ {10}ë¶„ + ì´ì†¡ {10}ë¶„ = ì´ {33}ë¶„")

# 4. Medical History Enrichment
df_history_silver = df_history.copy()
df_history_silver["icd_code"] = df_history_silver["diagnosis"].str.extract(r"\(([A-Z]\d+\.?\d*)\)")
df_history_silver["diagnosis_clean"] = df_history_silver["diagnosis"].str.replace(r"\s*\([A-Z]\d+\.?\d*\)", "", regex=True)

silver_history_path = os.path.join(OUTPUT_DIR, "silver", "refined_history")
os.makedirs(silver_history_path, exist_ok=True)
df_history_silver.to_parquet(os.path.join(silver_history_path, "data.parquet"), index=False)

print(f"\n  â”€â”€ ì˜ë£Œ íˆìŠ¤í† ë¦¬ (Silver) â”€â”€")
print(df_history_silver[["record_date", "diagnosis_clean", "icd_code", "medication"]].to_string(index=False))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GOLD LAYER â€” Aggregation & Clinical Summary
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "â”" * 70)
print("  [GOLD] Patient Clinical Summary Aggregation")
print("â”" * 70)

vital_agg = {
    "total_measurements": len(df_vitals_filtered),
    "avg_heart_rate": round(df_vitals_filtered["heart_rate"].mean(), 1),
    "min_heart_rate": round(df_vitals_filtered["heart_rate"].min(), 1),
    "max_heart_rate": round(df_vitals_filtered["heart_rate"].max(), 1),
    "avg_systolic_bp": round(df_vitals_filtered["systolic_bp"].mean(), 1),
    "avg_diastolic_bp": round(df_vitals_filtered["diastolic_bp"].mean(), 1),
    "avg_spo2": round(df_vitals_filtered["spo2"].mean(), 1),
    "min_spo2": round(df_vitals_filtered["spo2"].min(), 1),
    "max_spo2": round(df_vitals_filtered["spo2"].max(), 1),
    "avg_temperature": round(df_vitals_filtered["temperature"].mean(), 2),
    "max_temperature": round(df_vitals_filtered["temperature"].max(), 2),
    "avg_respiratory_rate": round(df_vitals_filtered["respiratory_rate"].mean(), 1),
    "avg_risk_score": round(df_vitals_filtered["risk_score"].mean(), 1),
    "max_risk_score": round(df_vitals_filtered["risk_score"].max(), 1),
    "alert_count": alert_count,
    "critical_count": int((df_vitals_filtered["risk_level"] == "CRITICAL").sum()),
}

gold_vitals_path = os.path.join(OUTPUT_DIR, "gold", "patient_vital_summary")
os.makedirs(gold_vitals_path, exist_ok=True)
pd.DataFrame([vital_agg]).to_parquet(os.path.join(gold_vitals_path, "data.parquet"), index=False)

print("\n  â”€â”€ í™˜ì ë°”ì´íƒˆ ì§‘ê³„ (Gold) â”€â”€")
print(f"  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
print(f"  â”‚ Heart Rate         â”‚ avg {vital_agg['avg_heart_rate']:>6.1f}  "
      f"min {vital_agg['min_heart_rate']:>6.1f}  "
      f"max {vital_agg['max_heart_rate']:>6.1f} â”‚")
print(f"  â”‚ Blood Pressure     â”‚ avg {vital_agg['avg_systolic_bp']:>5.1f} / {vital_agg['avg_diastolic_bp']:>5.1f} mmHg"
      f"             â”‚")
print(f"  â”‚ SpO2               â”‚ avg {vital_agg['avg_spo2']:>6.1f}%  "
      f"min {vital_agg['min_spo2']:>6.1f}%  "
      f"max {vital_agg['max_spo2']:>5.1f}% â”‚")
print(f"  â”‚ Temperature        â”‚ avg {vital_agg['avg_temperature']:>6.2f}Â°C  "
      f"max {vital_agg['max_temperature']:>6.2f}Â°C           â”‚")
print(f"  â”‚ Respiratory Rate   â”‚ avg {vital_agg['avg_respiratory_rate']:>6.1f}                        â”‚")
print(f"  â”‚ Risk Score         â”‚ avg {vital_agg['avg_risk_score']:>6.1f}  "
      f"max {vital_agg['max_risk_score']:>6.1f}               â”‚")
print(f"  â”‚ Alerts / Critical  â”‚ {vital_agg['alert_count']:>3d} alerts, "
      f"{vital_agg['critical_count']:>3d} critical episodes    â”‚")
print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# Vital trend (first 5, last 5)
print("\n  â”€â”€ ë°”ì´íƒˆ ì‹œê³„ì—´ íŠ¸ë Œë“œ (ì…ì› ì´ˆê¸° vs ì•ˆì •ê¸°) â”€â”€")
print("  [ ì…ì› ì´ˆê¸° (first 5) ]")
print(df_vitals_filtered[["timestamp", "heart_rate", "systolic_bp", "spo2", "temperature", "risk_score"]].head(5).to_string(index=False))
print("  [ ì•ˆì •ê¸° (last 5) ]")
print(df_vitals_filtered[["timestamp", "heart_rate", "systolic_bp", "spo2", "temperature", "risk_score"]].tail(5).to_string(index=False))

# Gold clinical profile
gold_profile = {
    "patient_id": "M00001",
    "patient_name": "Kim Cheolsu",
    "age": AGE,
    "gender": GENDER,
    "blood_type": BLOOD_TYPE,
    "admission_type": "Emergency",
    "hospital": str(df_emergency.iloc[0].get("hospital", "N/A")),
    "chief_complaint": str(df_emergency.iloc[0].get("chief_complaint", "N/A")),
    "triage_level": str(df_emergency.iloc[0].get("triage_level", "N/A")),
    "primary_diagnosis": str(df_emergency.iloc[0].get("suspected_diagnosis", "N/A")),
    "prehospital_time_min": 33,
    "medical_history_count": len(df_history_silver),
    "comorbidities": ", ".join(df_history_silver["diagnosis_clean"].tolist()),
    **vital_agg,
}

gold_profile_path = os.path.join(OUTPUT_DIR, "gold", "clinical_profile")
os.makedirs(gold_profile_path, exist_ok=True)
pd.DataFrame([gold_profile]).to_parquet(os.path.join(gold_profile_path, "data.parquet"), index=False)
print("\n  âœ“ Gold Clinical Profile saved")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI INFERENCE â€” Clinical Decision Support (ì‹œë®¬ë ˆì´ì…˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "â”" * 70)
print("  [AI INFERENCE] OpenAI GPT-4 Clinical Report (ì‹œë®¬ë ˆì´ì…˜)")
print("â”" * 70)

ai_report = {
    "patient_id": "M00001",
    "patient_name": "Kim Cheolsu",
    "model": "OpenAI GPT-4 (ì‹œë®¬ë ˆì´ì…˜)",
    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "clinical_assessment": {
        "primary_diagnosis": "Acute Pulmonary Tuberculosis Exacerbation with Respiratory Distress",
        "severity": "CRITICAL â†’ Stabilizing",
        "confidence": 0.92,
        "differential_diagnosis": [
            "Pulmonary TB reactivation (most likely)",
            "Bacterial pneumonia superinfection",
            "Lung abscess",
            "Pulmonary hemorrhage",
        ],
        "key_findings": [
            f"ì…ì› ì‹œ SpO2 88% â†’ ì¹˜ë£Œ í›„ {vital_agg['max_spo2']:.0f}%ë¡œ ê°œì„ ",
            f"ì´ˆê¸° ë¹ˆë§¥ (HR 118) â†’ {vital_agg['min_heart_rate']:.0f}ìœ¼ë¡œ ì•ˆì •í™”",
            f"ë°œì—´ 38.7Â°C, ê°í˜ˆ ë™ë°˜",
            "í‰ë¶€ X-ray: ìš°ìƒì—½ ê³µë™ì„± ë³‘ë³€ (Cavity) ì˜ì‹¬",
            f"ì´ {alert_count}íšŒ ì„ìƒ ê²½ë³´ ë°œìƒ (4ì‹œê°„ ëª¨ë‹ˆí„°ë§)",
            f"ê³¼ê±° íê²°í•µ ì¹˜ë£Œë ¥ (2021), COPD ë™ë°˜",
        ],
    },
    "soap_note": {
        "S": ("í™˜ì ê¹€ì² ìˆ˜(58/M)ëŠ” ê¸‰ì„± í˜¸í¡ê³¤ë€, ê°í˜ˆ, ë°œì—´(38.7Â°C)ì„ ì£¼ì†Œë¡œ "
              "119ë¥¼ í†µí•´ ì„œìš¸ëŒ€í•™êµë³‘ì› ì‘ê¸‰ì˜ë£Œì„¼í„°ì— ë‚´ì›í•˜ì˜€ìŠµë‹ˆë‹¤. "
              "ê³¼ê±°ë ¥: 2021ë…„ íê²°í•µ(A15.0) 6ê°œì›” ì¹˜ë£Œ ì™„ë£Œ, "
              "2018ë…„ë¶€í„° ê³ í˜ˆì••(I10), 2019ë…„ë¶€í„° 2í˜• ë‹¹ë‡¨(E11) ê´€ë¦¬ ì¤‘, "
              "2024ë…„ ì¤‘ë“±ë„ COPD(J44.1) ì§„ë‹¨. "
              "ìµœê·¼ 1ì£¼ê°„ ê¸°ì¹¨ ì•…í™” ë° ê°„í—ì  ê°í˜ˆ í˜¸ì†Œ."),
        "O": (f"V/S ì§‘ê³„(4h): HR avg {vital_agg['avg_heart_rate']:.0f} "
              f"(range {vital_agg['min_heart_rate']:.0f}-{vital_agg['max_heart_rate']:.0f}), "
              f"BP avg {vital_agg['avg_systolic_bp']:.0f}/{vital_agg['avg_diastolic_bp']:.0f}, "
              f"SpO2 avg {vital_agg['avg_spo2']:.1f}% (min {vital_agg['min_spo2']:.1f}%), "
              f"BT max {vital_agg['max_temperature']:.1f}Â°C, "
              f"RR avg {vital_agg['avg_respiratory_rate']:.0f}.\n"
              f"Risk Score: avg {vital_agg['avg_risk_score']:.1f}, max {vital_agg['max_risk_score']:.1f}.\n"
              f"Clinical alerts: {alert_count}/{vital_agg['total_measurements']} measurements triggered.\n"
              "CXR (portable PA): Right upper lobe cavitary lesion with perifocal consolidation. "
              "No pleural effusion. Trachea midline."),
        "A": ("1. Pulmonary TB reactivation with cavitary disease (A15.0)\n"
              "2. Acute respiratory failure, improving (initial SpO2 88%)\n"
              "3. Hemoptysis â€” likely from cavitary erosion into bronchial vessels\n"
              "4. Background: Essential HTN (I10), T2DM (E11), COPD (J44.1)\n"
              "5. Risk: Drug-resistant TB pending culture sensitivity"),
        "P": ("1. Airborne isolation (N95 + negative pressure room)\n"
              "2. Sputum AFB smear/culture Ã— 3, GeneXpert MTB/RIF\n"
              "3. Restart anti-TB: HERZ regimen "
              "(INH 300mg + RIF 600mg + EMB 800mg + PZA 1500mg daily)\n"
              "4. O2 therapy via non-rebreather â†’ maintain SpO2 >94%\n"
              "5. CT chest with contrast â€” cavitary extent, r/o abscess\n"
              "6. Labs: CBC, CRP, ESR, LFT (baseline for anti-TB), RFT, HbA1c\n"
              "7. ABG if SpO2 deteriorates\n"
              "8. Pulmonology and Infectious Disease consult\n"
              "9. Hemoptysis monitoring â€” IR consult if >200mL/24h\n"
              "10. Continue amlodipine 5mg, losartan 50mg, metformin 500mg bid\n"
              "11. Tiotropium inhaler continue"),
    },
    "treatment_recommendation": {
        "immediate": [
            "AFB isolation (airborne precautions, negative pressure room)",
            "O2 via non-rebreather mask 10-15L/min, target SpO2 >94%",
            "IV access Ã— 2, NS 500mL bolus",
            "Anti-TB: HERZ restart (INH + RIF + EMB + PZA)",
            "Antipyretics: Acetaminophen 1g IV PRN if BT >38.5Â°C",
        ],
        "diagnostic": [
            "Sputum AFB smear/culture Ã— 3 (spot, early morning, spot)",
            "GeneXpert MTB/RIF (rapid molecular test)",
            "CT Chest with contrast",
            "CBC, CRP, ESR, Procalcitonin",
            "LFT, RFT, HbA1c, Electrolytes",
            "Blood gas analysis (ABG)",
            "Blood cultures Ã— 2 sets",
        ],
        "monitoring": [
            "Continuous SpO2 + telemetry",
            "Vital signs q15min Ã— 2hr, then q30min",
            "Strict I/O charting",
            "Hemoptysis volume tracking (emesis basin)",
            "Repeat CXR in 48-72 hours",
        ],
    },
}

# Save AI results
ai_results_path = os.path.join(OUTPUT_DIR, "ai_results")
os.makedirs(ai_results_path, exist_ok=True)
with open(os.path.join(ai_results_path, "clinical_report.json"), "w", encoding="utf-8") as f:
    json.dump(ai_report, f, ensure_ascii=False, indent=2)

print("  âœ“ AI Clinical Report generated")
print("\n  â”€â”€ SOAP Note â”€â”€")
for section, content in ai_report["soap_note"].items():
    print(f"\n  [{section}]")
    for line in content.split("\n"):
        print(f"    {line}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LLM-as-a-Judge â€” Quality Evaluation (ì‹œë®¬ë ˆì´ì…˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n\n" + "â”" * 70)
print("  [LLM-as-a-Judge] AI Report Quality Evaluation (ì‹œë®¬ë ˆì´ì…˜)")
print("â”" * 70)

judge_eval = {
    "patient_id": "M00001",
    "model_evaluated": "GPT-4 (sim)",
    "judge_model": "GPT-4 Judge (sim)",
    "evaluation_timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    "criteria": {
        "accuracy": {
            "score": 9, "max": 10,
            "comment": "TB reactivation ì •í™• ì§„ë‹¨, ê°ë³„ì§„ë‹¨ 4ì¢… ì ì ˆ, confidence 0.92"
        },
        "completeness": {
            "score": 8, "max": 10,
            "comment": "SOAP ì „ í•­ëª© ì¶©ì‹¤, ì•½ë¬¼ ìš©ëŸ‰ ëª…ì‹œ. LFT baseline monitoring í¬í•¨."
        },
        "actionability": {
            "score": 9, "max": 10,
            "comment": "ì¦‰ê° ì¹˜ë£Œ 11ê°œ í•­ëª©, ìš°ì„ ìˆœìœ„ ëª…í™• (isolation â†’ O2 â†’ anti-TB)"
        },
        "safety": {
            "score": 10, "max": 10,
            "comment": "Airborne isolation ìµœìš°ì„ , LFT baseline (anti-TB ê°„ë…ì„±), ì•½ë¬¼ ìƒí˜¸ì‘ìš© ê³ ë ¤"
        },
        "relevance": {
            "score": 9, "max": 10,
            "comment": "í™˜ì ê³¼ê±°ë ¥(TB ì¹˜ë£Œë ¥, COPD, HTN/DM) ì ì ˆ ë°˜ì˜, ë™ë°˜ì§ˆí™˜ ê´€ë¦¬ ìœ ì§€"
        },
    },
    "total_score": 45,
    "max_score": 50,
    "percentage": 90.0,
    "verdict": "PASS",
    "group": "A (Original AI Report)",
    "feedback": (
        "ì „ë°˜ì ìœ¼ë¡œ ë†’ì€ í’ˆì§ˆì˜ ì„ìƒ ë³´ê³ ì„œì…ë‹ˆë‹¤. "
        "ê°œì„  ê¶Œì¥ ì‚¬í•­: (1) Drug-resistant TB ê°€ëŠ¥ì„±ì— ëŒ€í•œ ê²½í—˜ì  ì¹˜ë£Œ ê³ ë ¤, "
        "(2) ì ‘ì´‰ì ì¶”ì  ë° ê³µì¤‘ë³´ê±´ ì‹ ê³  ì ˆì°¨ ì¶”ê°€, "
        "(3) ì˜ì–‘ ìƒíƒœ í‰ê°€ ë° ì§€ì› ê³„íš ì¶”ê°€."
    ),
}

with open(os.path.join(ai_results_path, "judge_evaluation.json"), "w", encoding="utf-8") as f:
    json.dump(judge_eval, f, ensure_ascii=False, indent=2)

print(f"\n  Judge Verdict: {judge_eval['verdict']}  "
      f"({judge_eval['total_score']}/{judge_eval['max_score']} = {judge_eval['percentage']}%)")
print(f"  â”Œ{'â”€'*60}â”")
for k, v in judge_eval["criteria"].items():
    bar = "â–ˆ" * v["score"] + "â–‘" * (v["max"] - v["score"])
    print(f"  â”‚ {k:15s} {bar} {v['score']:>2d}/{v['max']}  {v['comment'][:30]}â”‚")
print(f"  â””{'â”€'*60}â”˜")
print(f"\n  Feedback: {judge_eval['feedback']}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORRECTION (Group B) â€” Judge ê¸°ë°˜ ë³´ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "â”" * 70)
print("  [CORRECTION] Judge í”¼ë“œë°± ê¸°ë°˜ ë³´ì • (Group Bìš©)")
print("â”" * 70)

correction = {
    "patient_id": "M00001",
    "original_score": 45,
    "corrections_applied": [
        {
            "category": "completeness",
            "original": "Drug-resistant TB ê³ ë ¤ ë¯¸í¡",
            "corrected": "ê²½í—˜ì  MDR-TB ì¹˜ë£Œ ê³ ë ¤: Moxifloxacin 400mg daily ì¶”ê°€ "
                         "pending GeneXpert result",
        },
        {
            "category": "completeness",
            "original": "ê³µì¤‘ë³´ê±´ ì‹ ê³  ì ˆì°¨ ë¯¸ê¸°ì¬",
            "corrected": "ê²°í•µ í™•ì§„ ì‹œ ê´€í•  ë³´ê±´ì†Œ ì‹ ê³  (ê°ì—¼ë³‘ì˜ˆë°©ë²• ì œ11ì¡°), "
                         "ì ‘ì´‰ì ì¶”ì  ê²€ì‚¬ ì˜ë¢°",
        },
        {
            "category": "completeness",
            "original": "ì˜ì–‘ í‰ê°€ ë¯¸í¬í•¨",
            "corrected": "BMI ì¸¡ì •, ì•Œë¶€ë¯¼/í”„ë¦¬ì•Œë¶€ë¯¼ ê²€ì‚¬, ì˜ì–‘ ìƒë‹´ ì˜ë¢°. "
                         "TB í™˜ì ê³ ì¹¼ë¡œë¦¬ ì‹ì´ ê³„íš.",
        },
    ],
    "corrected_score": 48,
    "improvement": "+3 points (90% â†’ 96%)",
}

with open(os.path.join(ai_results_path, "correction_summary.json"), "w", encoding="utf-8") as f:
    json.dump(correction, f, ensure_ascii=False, indent=2)

for c in correction["corrections_applied"]:
    print(f"  âœ  [{c['category']}]")
    print(f"     Before: {c['original']}")
    print(f"     After:  {c['corrected']}")

print(f"\n  Score improvement: {correction['original_score']} â†’ {correction['corrected_score']} "
      f"({correction['improvement']})")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FINAL SUMMARY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n\n" + "=" * 70)
print("  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
print("  â•‘       ê¹€ì² ìˆ˜ (M00001) â€” End-to-End Pipeline Complete        â•‘")
print("  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
print("=" * 70)

print(f"""
  í™˜ì: ê¹€ì² ìˆ˜ (Kim Cheolsu, 58/M, A+)
  ì§„ë‹¨: Acute Pulmonary TB Exacerbation
  ì…ì›: Emergency, ì„œìš¸ëŒ€í•™êµë³‘ì›

  â”â”â” Pipeline Results â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  [BRONZE] Raw Ingestion    â†’ 4 datasets (emergency/history/vitals/imaging)
  [SILVER] Refinement       â†’ Outliers:{removed}, Alerts:{alert_count}/{vital_agg['total_measurements']}
  [GOLD]   Aggregation      â†’ HR avg:{vital_agg['avg_heart_rate']}, SpO2 avg:{vital_agg['avg_spo2']}%
  [AI]     Clinical Report  â†’ SOAP note + Treatment plan generated
  [JUDGE]  Quality Eval     â†’ {judge_eval['total_score']}/{judge_eval['max_score']} ({judge_eval['percentage']}%) {judge_eval['verdict']}
  [CORRECT] Feedback Loop   â†’ {correction['original_score']} â†’ {correction['corrected_score']} ({correction['improvement']})
  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
""")

# Output folder tree
print("  ğŸ“ Output Structure:")
for root, dirs, files in os.walk(OUTPUT_DIR):
    level = root.replace(OUTPUT_DIR, "").count(os.sep)
    indent = "     " + "  " * level
    basename = os.path.basename(root)
    print(f"{indent}ğŸ“‚ {basename}/")
    file_indent = "     " + "  " * (level + 1)
    for file in files:
        size_kb = os.path.getsize(os.path.join(root, file)) / 1024
        icon = "ğŸ“Š" if file.endswith(".parquet") else "ğŸ“„"
        print(f"{file_indent}{icon} {file}  ({size_kb:.1f} KB)")

print("\n  âœ… Pipeline execution complete!")
