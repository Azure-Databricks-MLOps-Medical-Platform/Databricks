{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Î≥¥Ï†ï ÏöîÏïΩ Í≤∞Í≥º ÏÉùÏÑ± (Correction Summary)\n",
                "\n",
                "> **Purpose:** LLM-as-a-Judge ÌèâÍ∞Ä Í≤∞Í≥ºÎ•º Í∏∞Î∞òÏúºÎ°ú AI SOAP ÎÖ∏Ìä∏Ïùò Î≥¥Ï†ï ÏöîÏïΩÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
                "> - Judge Ï†êÏàò < 4.0Ïù∏ SOAP ÎÖ∏Ìä∏Î•º ÎåÄÏÉÅÏúºÎ°ú Î≥¥Ï†ï Ïã§Ìñâ\n",
                "> - Î≥¥Ï†ï Í≤∞Í≥ºÎ•º `P2T2.ai_results.correction_summary` ÌÖåÏù¥Î∏îÏóê Ï†ÄÏû•\n",
                ">\n",
                "> **Ïπ¥ÌÉàÎ°úÍ∑∏:** `P2T2`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. Ïπ¥ÌÉàÎ°úÍ∑∏ ÏÑ§Ï†ï"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark.sql(\"USE CATALOG P2T2\")\n",
                "print(\"‚úÖ Catalog: P2T2\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÏÑ§Ï†ï"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import openai\n",
                "import json\n",
                "from pyspark.sql import functions as F\n",
                "\n",
                "# Azure OpenAI\n",
                "CORRECTION_API_KEY = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"openai-api-key\")\n",
                "CORRECTION_ENDPOINT = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"openai-endpoint\")\n",
                "\n",
                "client = openai.AzureOpenAI(\n",
                "    azure_endpoint=CORRECTION_ENDPOINT,\n",
                "    api_key=CORRECTION_API_KEY,\n",
                "    api_version=\"2025-01-01-preview\"\n",
                ")\n",
                "\n",
                "CORRECTION_MODEL = \"gpt-51-deploy\"\n",
                "print(\"‚úÖ Correction ÏÑ§Ï†ï ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Î≥¥Ï†ï ÌîÑÎ°¨ÌîÑÌä∏"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "CORRECTION_PROMPT = \"\"\"\n",
                "Based on the following LLM-as-a-Judge evaluation, generate a corrected and improved \n",
                "clinical summary. Focus on fixing identified issues and enhancing clarity.\n",
                "\n",
                "## Original SOAP Note:\n",
                "{original_soap}\n",
                "\n",
                "## Judge Evaluation:\n",
                "{judge_evaluation}\n",
                "\n",
                "## Corrections Needed:\n",
                "{corrections_needed}\n",
                "\n",
                "## Instructions:\n",
                "1. Address all identified corrections\n",
                "2. Maintain medical accuracy\n",
                "3. Keep actionable recommendations\n",
                "4. Write concise ER physician-ready format\n",
                "5. Include confidence level\n",
                "\n",
                "Output a corrected clinical summary (max 500 words).\n",
                "\"\"\"\n",
                "\n",
                "print(\"‚úÖ Î≥¥Ï†ï ÌîÑÎ°¨ÌîÑÌä∏ Ï†ïÏùò ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Î≥¥Ï†ï ÏöîÏïΩ ÏÉùÏÑ±"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def generate_correction(patient_id, original_soap, judge_evaluation):\n",
                "    \"\"\"\n",
                "    Judge ÌèâÍ∞ÄÎ•º Î∞òÏòÅÌïú Î≥¥Ï†ï ÏöîÏïΩÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
                "    \"\"\"\n",
                "    corrections = judge_evaluation.get(\"corrections_needed\", [])\n",
                "    \n",
                "    prompt = CORRECTION_PROMPT.format(\n",
                "        original_soap=original_soap,\n",
                "        judge_evaluation=json.dumps(judge_evaluation, ensure_ascii=False, default=str),\n",
                "        corrections_needed=\"\\n\".join(f\"- {c}\" for c in corrections) if corrections else \"No major corrections.\",\n",
                "    )\n",
                "    \n",
                "    try:\n",
                "        response = client.chat.completions.create(\n",
                "            model=CORRECTION_MODEL,\n",
                "            messages=[\n",
                "                {\"role\": \"system\", \"content\": \"Medical document editor. Accuracy and clarity.\"},\n",
                "                {\"role\": \"user\", \"content\": prompt},\n",
                "            ],\n",
                "            max_completion_tokens=800,\n",
                "            temperature=0.2,\n",
                "        )\n",
                "        summary = response.choices[0].message.content or \"[Content filtered]\"\n",
                "        overall_score = judge_evaluation.get(\"overall_score\", 0.0)\n",
                "        confidence = judge_evaluation.get(\"confidence\", 0.0)\n",
                "        adjusted = min(1.0, (overall_score / 5.0 + confidence) / 2)\n",
                "        \n",
                "        return {\"patient_id\": patient_id, \"summary\": summary, \"confidence\": str(round(adjusted, 3))}\n",
                "    except Exception as e:\n",
                "        return {\"patient_id\": patient_id, \"summary\": f\"Error: {str(e)}\", \"confidence\": \"0.0\"}\n",
                "\n",
                "print(\"‚úÖ Î≥¥Ï†ï ÏöîÏïΩ Ìï®Ïàò Ï§ÄÎπÑ ÏôÑÎ£å\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Î∞∞Ïπò Î≥¥Ï†ï Î∞è Ï†ÄÏû•"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "def batch_correction_summary():\n",
                "    \"\"\"\n",
                "    Judge Ï†êÏàò < 4.0Ïù∏ SOAP ÎÖ∏Ìä∏Î•º Î≥¥Ï†ïÌïòÏó¨ Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
                "    \"\"\"\n",
                "    df = spark.sql(\"\"\"\n",
                "        SELECT \n",
                "            j.patient_id,\n",
                "            j.evaluation_json,\n",
                "            j.overall_score,\n",
                "            s.soap_note\n",
                "        FROM P2T2.ai_results.judge_evaluation j\n",
                "        JOIN P2T2.ai_results.openai_soap_notes s ON j.patient_id = s.patient_id\n",
                "        WHERE CAST(j.overall_score AS DOUBLE) < 4.0\n",
                "        ORDER BY CAST(j.overall_score AS DOUBLE) ASC\n",
                "    \"\"\")\n",
                "    \n",
                "    rows = df.collect()\n",
                "    results = []\n",
                "    \n",
                "    print(f\"üìù Î≥¥Ï†ï ÎåÄÏÉÅ: {len(rows)}Í±¥ (Judge < 4.0)\")\n",
                "    \n",
                "    for row in rows:\n",
                "        evaluation = json.loads(row[\"evaluation_json\"])\n",
                "        result = generate_correction(\n",
                "            patient_id=row[\"patient_id\"],\n",
                "            original_soap=row[\"soap_note\"],\n",
                "            judge_evaluation=evaluation,\n",
                "        )\n",
                "        results.append(result)\n",
                "    \n",
                "    if results:\n",
                "        df_results = spark.createDataFrame(results)\n",
                "        df_results = df_results.withColumn(\"processed_at\", F.current_timestamp())\n",
                "        \n",
                "        df_results.write \\\n",
                "            .format(\"delta\") \\\n",
                "            .mode(\"overwrite\") \\\n",
                "            .option(\"overwriteSchema\", \"true\") \\\n",
                "            .saveAsTable(\"P2T2.ai_results.correction_summary\")\n",
                "        \n",
                "        print(f\"‚úÖ Î≥¥Ï†ï Ï†ÄÏû•: {len(results)}Í±¥ ‚Üí P2T2.ai_results.correction_summary\")\n",
                "    else:\n",
                "        print(\"‚ÑπÔ∏è Î≥¥Ï†ï ÎåÄÏÉÅ ÏóÜÏùå (Î™®Îì† SOAP Ï†êÏàò ‚â• 4.0)\")\n",
                "\n",
                "batch_correction_summary()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}